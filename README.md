# MR-MKG: Multimodal Reasoning with Multimodal Knowledge Graphs

This repository is an implementation of the ICLR 2024 paper:
**"Multimodal Reasoning with Multimodal Knowledge Graphs" (MR-MKG)**.
It supports visual-textual reasoning using knowledge-enhanced LLMs with no LLM fine-tuning.

---

## Project Structure

```
mr-mkg/
â”œâ”€â”€ train.py                  # í•™ìŠµ ì „ì²´ íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ inference.py              # ì„ì˜ ì§ˆë¬¸ + ì´ë¯¸ì§€ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ test.py                   # test set ê¸°ë°˜ í‰ê°€
â”œâ”€â”€ validate.py               # validation loss í‰ê°€ìš© ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ models/                   # ëª¨ë¸ êµ¬ì„± ëª¨ë“ˆ
â”‚   â”œâ”€â”€ mr_mkg.py             # ì „ì²´ MR-MKG ëª¨ë¸ ì •ì˜
â”‚   â”œâ”€â”€ encoders.py           # LanguageEncoder, KGEncoder(RGAT)
â”‚   â”œâ”€â”€ adapters.py           # VisualAdapter, KnowledgeAdapter
â”‚   â”œâ”€â”€ rgat.py               # RGAT layer ì •ì˜
â”‚   â””â”€â”€ cross_modal_align.py  # ì´ë¯¸ì§€-ì—”í‹°í‹° ì •ë ¬ loss (Triplet)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ build_mmkg.py         # ScienceQA â†’ MMKG ë³€í™˜
â”‚   â”œâ”€â”€ generate_mmkg_dataset.py # ì „ì²´ ë°ì´í„°ì…‹ êµ¬ì¶• ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ load_scienceqa.py     # ScienceQA í¬ë§· ë¡œë”©
â”‚   â”œâ”€â”€ mrmkg_dataset.py      # í•™ìŠµìš© MMKG Dataset í´ë˜ìŠ¤
â”‚   â””â”€â”€ scienceqa/            # ì›ë³¸ ë°ì´í„° ì €ì¥ ìœ„ì¹˜
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ graph_utils.py        # NetworkX â†’ DGL ë³€í™˜, subgraph ì¶”ì¶œ
â”‚   â”œâ”€â”€ visual_feature.py     # CLIP ì„ë² ë”© ë° ì´ˆê¸°í™”
â”‚   â””â”€â”€ align_utils.py        # cross-modal triplet loss ê³„ì‚°
â”‚
â””â”€â”€ README.md   
```

---

## Method Overview

MR-MKG introduces a pipeline to integrate multimodal knowledge graphs into a frozen LLM using:

- **CLIP**: for image feature extraction
- **Visual Adapter**: linear projection to LLM space
- **RGAT**: for knowledge graph (MMKG) encoding
- **Knowledge Adapter**: attention-based summarization of KG embeddings
- **Prompt Injection**: `[IMAGE]`, `[KNOWLEDGE]` tokens are replaced with respective embeddings
- **Triplet Loss**: alignment between image & KG representations

---

## Setup

### 1. Install dependencies
```bash
pip install -r requirements.txt
```

If using PyTorch Geometric:
```bash
pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric \
  -f https://data.pyg.org/whl/torch-<torch_version>.html
```

### 2. Download and prepare ScienceQA
Place the `problems.json`, `pid_splits.json`, `captions.json`, and image folders into:
```
data/scienceqa/
â”œâ”€â”€ train/<pid>/image.png
â”œâ”€â”€ val/<pid>/image.png
â”œâ”€â”€ test/<pid>/image.png
â”œâ”€â”€ problems.json
â”œâ”€â”€ pid_splits.json
â””â”€â”€ captions.json
```

### 3. Generate MMKG graphs
```bash
python data/generate_mmkg_dataset.py
```

---

### Model Architecture 
```pgsql
Input: [text prompt] + [image] + [entity KG]

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚     Language Encoder      â”‚ â† input_ids
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚       Prompt Embedding     â”‚ = HT + HK + HI
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚        â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”      â”Œâ–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ KGEncoder â”‚      â”‚ VisualAdapterâ”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”˜      â””â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚        â”‚
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
                       â–¼
                  T5 (frozen)
                       â”‚
                    Answer

```

## Training
```bash
python train.py
```
Logs training & validation loss across epochs with both generative and alignment loss.

---

## Evaluation
```bash
python validate.py    # validation set
python test.py        # test set

```


## Inference
```bash
python inference.py
```
Enter a question: What is this?
Enter an image path (or leave empty for no image): ./images/eiffel.jpg

---

## Citation
If you use this code, please consider citing the original paper:

```bibtex
@inproceedings{diao2024mrmkg,
  title={Multimodal Reasoning with Multimodal Knowledge Graphs},
  author={Diao, Haotian and Zhang, Junnan and Zhang, Xiyang and Lin, Dahua and Wang, Yichen},
  booktitle={ICLR},
  year={2024}
}
```

---

## ğŸ’¬ Contact
For any questions, feel free to reach out via [issues](https://github.com/DasolJeong/mr-mkg/issues) or email.

---
